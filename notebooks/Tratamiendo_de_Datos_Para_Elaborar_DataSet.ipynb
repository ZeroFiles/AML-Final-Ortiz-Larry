{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 00) MONTAJE DE GOOGLE DRIVE\n",
        "# =====================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_PATH = '/content/drive/MyDrive/AML_Final_Project/'\n",
        "print(\"âœ… Google Drive montado\")\n",
        "print(f\"ðŸ“‚ Ruta base del proyecto: {BASE_PATH}\")\n",
        "\n",
        "# =====================================================\n",
        "# 01) LIBRERÃAS\n",
        "# =====================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# =====================================================\n",
        "# 02) PARÃMETROS\n",
        "# =====================================================\n",
        "INPUT_FILE = BASE_PATH + \"datasetPrevio.xlsx\"\n",
        "OUTPUT_FILE = BASE_PATH + \"dataset_model.parquet\"\n",
        "\n",
        "# Si quieres alinear horas a PerÃº (recomendado si tus picos son hora local)\n",
        "USE_LIMA_TZ = True\n",
        "LIMA_TZ = \"America/Lima\"\n",
        "\n",
        "# Completar grilla por local: frecuencia horaria\n",
        "FREQ = \"h\"\n",
        "\n",
        "# Filtrado por horas operativas detectadas por local (reduce ceros estructurales)\n",
        "FILTER_OPERATING_HOURS = True\n",
        "\n",
        "# Lags / rolling (arranca con tamaÃ±os razonables)\n",
        "LAGS = [1, 2, 3, 24, 168]         # 1h,2h,3h,1d\n",
        "ROLL_WINDOWS = [6, 12, 24, 168]   # 6h,12h,24h\n",
        "\n",
        "# Min porcentaje de pedidos > 0 para considerar una hora como \"operativa\" (por local)\n",
        "OPER_HOUR_MIN_POS_RATE = 0.02  # 2% de las observaciones con demanda>0\n",
        "\n",
        "# =====================================================\n",
        "# 03) CARGA\n",
        "# =====================================================\n",
        "df = pd.read_excel(INPUT_FILE)\n",
        "print(\"Shape original:\", df.shape)\n",
        "\n",
        "# =====================================================\n",
        "# 04) TIPOS Y LIMPIEZA\n",
        "# =====================================================\n",
        "df[\"fecha_creacion_fv\"] = pd.to_datetime(df[\"fecha_creacion_fv\"], errors=\"coerce\", utc=True)\n",
        "\n",
        "for col in [\"KM_REAL\", \"TIEMPO_ENTREGA_RETORNO\"]:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "df = df.dropna(subset=[\"fecha_creacion_fv\", \"local\"])\n",
        "\n",
        "# Convertir a Lima si aplica (para que la hora sea la real del negocio)\n",
        "if USE_LIMA_TZ:\n",
        "    df[\"fecha_creacion_fv\"] = df[\"fecha_creacion_fv\"].dt.tz_convert(LIMA_TZ)\n",
        "\n",
        "# Bucket horario (ojo: floor('H') -> floor('h'))\n",
        "df[\"ts_hour\"] = df[\"fecha_creacion_fv\"].dt.floor(\"h\")\n",
        "df[\"hora\"] = df[\"ts_hour\"].dt.hour\n",
        "\n",
        "# =====================================================\n",
        "# 05) AGREGACIÃ“N BASE (local-hora) SIN REINDEX AÃšN\n",
        "# =====================================================\n",
        "base = (\n",
        "    df.groupby([\"local\", \"ts_hour\"], as_index=False)\n",
        "      .agg(\n",
        "          pedidos=(\"order_id\", \"count\"),\n",
        "          km_mean=(\"KM_REAL\", \"mean\"),\n",
        "          t_ret_mean=(\"TIEMPO_ENTREGA_RETORNO\", \"mean\"),\n",
        "          t_ret_p75=(\"TIEMPO_ENTREGA_RETORNO\",\n",
        "                     lambda x: np.nanpercentile(x, 75) if np.isfinite(x).any() else np.nan)\n",
        "      )\n",
        ")\n",
        "\n",
        "# =====================================================\n",
        "# 06) FUNCIÃ“N: COMPLETAR GRILLA POR LOCAL EN SU RANGO ACTIVO\n",
        "# =====================================================\n",
        "def build_full_grid_per_local(base_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = []\n",
        "    for loc, b in base_df.groupby(\"local\", sort=False):\n",
        "        min_ts = b[\"ts_hour\"].min()\n",
        "        max_ts = b[\"ts_hour\"].max()\n",
        "        hours = pd.date_range(min_ts, max_ts, freq=FREQ, tz=min_ts.tz)  # conserva tz local\n",
        "\n",
        "        idx = pd.MultiIndex.from_product([[loc], hours], names=[\"local\", \"ts_hour\"])\n",
        "        b_full = (\n",
        "            b.set_index([\"local\", \"ts_hour\"])\n",
        "             .reindex(idx)\n",
        "             .reset_index()\n",
        "        )\n",
        "\n",
        "        # pedidos=0 cuando no hubo registros en esa hora (esto sÃ­ es correcto)\n",
        "        b_full[\"pedidos\"] = b_full[\"pedidos\"].fillna(0).astype(int)\n",
        "\n",
        "        # Para variables operativas: imputaciÃ³n robusta solo con info del local\n",
        "        for c in [\"km_mean\", \"t_ret_mean\", \"t_ret_p75\"]:\n",
        "            med = b[c].median()\n",
        "            b_full[c] = b_full[c].fillna(med)\n",
        "\n",
        "        out.append(b_full)\n",
        "\n",
        "    full = pd.concat(out, ignore_index=True)\n",
        "    return full\n",
        "\n",
        "base_full = build_full_grid_per_local(base)\n",
        "\n",
        "# Fallback global por si algÃºn local tuvo todo NaN en operativas (raro)\n",
        "for c in [\"km_mean\", \"t_ret_mean\", \"t_ret_p75\"]:\n",
        "    base_full[c] = base_full[c].fillna(base_full[c].median())\n",
        "\n",
        "# =====================================================\n",
        "# 07) (OPCIONAL) FILTRAR HORAS OPERATIVAS POR LOCAL\n",
        "#     - Evita incluir horas donde el local casi nunca opera\n",
        "# =====================================================\n",
        "base_full[\"hora\"] = base_full[\"ts_hour\"].dt.hour\n",
        "\n",
        "if FILTER_OPERATING_HOURS:\n",
        "    # tasa de horas con demanda>0 por local y hora\n",
        "    pos_rate = (\n",
        "        base_full.assign(pos=(base_full[\"pedidos\"] > 0).astype(int))\n",
        "                 .groupby([\"local\", \"hora\"])[\"pos\"].mean()\n",
        "                 .reset_index()\n",
        "                 .rename(columns={\"pos\": \"pos_rate\"})\n",
        "    )\n",
        "\n",
        "    base_full = base_full.merge(pos_rate, on=[\"local\", \"hora\"], how=\"left\")\n",
        "    base_full[\"pos_rate\"] = base_full[\"pos_rate\"].fillna(0)\n",
        "\n",
        "    # conservar solo horas que superen el umbral\n",
        "    base_full = base_full[base_full[\"pos_rate\"] >= OPER_HOUR_MIN_POS_RATE].copy()\n",
        "    base_full.drop(columns=[\"pos_rate\"], inplace=True)\n",
        "\n",
        "# =====================================================\n",
        "# 08) FEATURES TEMPORALES\n",
        "# =====================================================\n",
        "base_full[\"dow\"] = base_full[\"ts_hour\"].dt.dayofweek\n",
        "base_full[\"month\"] = base_full[\"ts_hour\"].dt.month\n",
        "base_full[\"is_weekend\"] = (base_full[\"dow\"] >= 5).astype(int)\n",
        "\n",
        "# Variables cÃ­clicas\n",
        "base_full[\"hora_sin\"] = np.sin(2 * np.pi * base_full[\"hora\"] / 24)\n",
        "base_full[\"hora_cos\"] = np.cos(2 * np.pi * base_full[\"hora\"] / 24)\n",
        "base_full[\"dow_sin\"] = np.sin(2 * np.pi * base_full[\"dow\"] / 7)\n",
        "base_full[\"dow_cos\"] = np.cos(2 * np.pi * base_full[\"dow\"] / 7)\n",
        "\n",
        "# Ordenar para lags/rolling\n",
        "base_full = base_full.sort_values([\"local\", \"ts_hour\"]).reset_index(drop=True)\n",
        "\n",
        "# =====================================================\n",
        "# 09) LAGS\n",
        "# =====================================================\n",
        "for lag in LAGS:\n",
        "    base_full[f\"pedidos_lag_{lag}h\"] = base_full.groupby(\"local\")[\"pedidos\"].shift(lag)\n",
        "\n",
        "# =====================================================\n",
        "# 10) ROLLING (sobre la serie ordenada por local)\n",
        "# =====================================================\n",
        "for w in ROLL_WINDOWS:\n",
        "    base_full[f\"pedidos_roll_mean_{w}h\"] = (\n",
        "        base_full.groupby(\"local\")[\"pedidos\"]\n",
        "                 .shift(1)\n",
        "                 .rolling(window=w, min_periods=max(2, w//3))\n",
        "                 .mean()\n",
        "                 .reset_index(level=0, drop=True)\n",
        "    )\n",
        "    base_full[f\"pedidos_roll_std_{w}h\"] = (\n",
        "        base_full.groupby(\"local\")[\"pedidos\"]\n",
        "                 .shift(1)\n",
        "                 .rolling(window=w, min_periods=max(2, w//3))\n",
        "                 .std()\n",
        "                 .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "# =====================================================\n",
        "# 11) VARIABLE DERIVADA (opcional)\n",
        "# =====================================================\n",
        "base_full[\"flota_requerida_estimada\"] = (base_full[\"pedidos\"] * base_full[\"t_ret_mean\"]) / 60\n",
        "\n",
        "# =====================================================\n",
        "# 12) FILTRADO FINAL (no mates todo)\n",
        "#     - Exige solo features clave (por ejemplo lag 1h + 24h + rolling 24h)\n",
        "# =====================================================\n",
        "required = [f\"pedidos_lag_{min(LAGS)}h\", \"pedidos_lag_24h\", \"pedidos_roll_mean_24h\"]\n",
        "df_model = base_full.dropna(subset=required).copy()\n",
        "\n",
        "print(\"âœ… Shape model-ready:\", df_model.shape)\n",
        "print(\"Rango fechas:\", df_model[\"ts_hour\"].min(), \"->\", df_model[\"ts_hour\"].max())\n",
        "print(\"Locales:\", df_model[\"local\"].nunique())\n",
        "\n",
        "print(\"\\nDistribuciÃ³n pedidos (model-ready):\")\n",
        "print(df_model[\"pedidos\"].describe())\n",
        "\n",
        "# =====================================================\n",
        "# 13) GUARDAR\n",
        "# =====================================================\n",
        "df_model.to_parquet(OUTPUT_FILE, index=False)\n",
        "print(\"\\nâœ… Dataset model-ready guardado en:\")\n",
        "print(OUTPUT_FILE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n03q47yjYqfx",
        "outputId": "efaa78c4-6dcf-41bb-9671-7ffabd7ccf77"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Google Drive montado\n",
            "ðŸ“‚ Ruta base del proyecto: /content/drive/MyDrive/AML_Final_Project/\n",
            "Shape original: (9504, 11)\n",
            "âœ… Shape model-ready: (19393, 28)\n",
            "Rango fechas: 2025-02-14 20:00:00-05:00 -> 2025-05-04 18:00:00-05:00\n",
            "Locales: 25\n",
            "\n",
            "DistribuciÃ³n pedidos (model-ready):\n",
            "count    19393.000000\n",
            "mean         0.443665\n",
            "std          2.797950\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%          0.000000\n",
            "max         81.000000\n",
            "Name: pedidos, dtype: float64\n",
            "\n",
            "âœ… Dataset model-ready guardado en:\n",
            "/content/drive/MyDrive/AML_Final_Project/dataset_model.parquet\n"
          ]
        }
      ]
    }
  ]
}